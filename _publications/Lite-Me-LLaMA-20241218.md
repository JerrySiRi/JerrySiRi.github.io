---
title: "Lite-Me-LLaMA: Resource-Efficient Large Language Models for Medical Applications"
collection: publications
category: manuscripts
permalink: /publication/Lite-Me-LLaMA-20241218
excerpt: 'To overcome the challenges of high costs, infrastructure demands, and data privacy concerns in medical applications of large language models (LLMs), we introduce Lite-Me-LLaMA, a suite of lightweight, open-source medical LLMs. By enhancing LLaMA3-8B with extensive medical pre-training and instruction fine-tuning, it is designed to be efficient, transparent, and readily deployable in clinical settings, requiring minimal computational resources for seamless integration into workflows while maintaining robust data privacy and security.'
date: 2024-12-18
venue: 'Journal of the American Medical Informatics Association, 2024'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'http://academicpages.github.io/files/MedLLaMA.pdf'
#bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
To overcome the challenges of high costs, infrastructure demands, and data privacy concerns in
medical applications of large language models (LLMs), we introduce Lite-Me-LLaMA, a suite of lightweight, open-source medical LLMs. By enhancing LLaMA3-8B with extensive medical pre-training and instruction fine-tuning, it is designed to be efficient, transparent, and readily deployable in clinical settings, requiring minimal computational resources for seamless integration into workflows while maintaining robust data privacy and security.
