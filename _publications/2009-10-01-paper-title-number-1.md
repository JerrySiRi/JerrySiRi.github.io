---
title: "ite-Me-LLaMA: Resource-Efficient Large Language
Models for Medical Applications"
collection: publications
category: manuscripts
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2025-02-18
venue: 'Journal 1'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
#paperurl: 'http://academicpages.github.io/files/paper1.pdf'
#bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
To overcome the challenges of high costs, infrastructure demands, and data privacy concerns in
medical applications of large language models (LLMs), we introduce Lite-Me-LLaMA, a suite of lightweight, open-source medical LLMs. By enhancing LLaMA3-8B with extensive medical pre-training and instruction fine-tuning, it is designed to be efficient, transparent, and readily deployable in clinical settings, requiring minimal computational resources for seamless integration into workflows while maintaining robust data privacy and security
